{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/sapjunior/chulacv2018/blob/master/Lab%206%20-%20Convolutional%20Neural%20Network.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdxWIn81cLW7"
   },
   "outputs": [],
   "source": [
    "## This Block is for Google Colaboratory user. Don't forget to enable GPU in Runtime->Change Runtime Type-> Hardware Accelerator -> GPU\n",
    "## Install missing packages for Google Colaboratory ##\n",
    "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install torchvision\n",
    "!pip3 install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rAHKE6R1Y5Rv"
   },
   "source": [
    "## Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8QUqix7a2Pc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import urllib\n",
    "import tarfile\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_84jZl2JrQe"
   },
   "source": [
    "## Setup Kaggle API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxBS6IicJhki"
   },
   "outputs": [],
   "source": [
    "# On the kaggle website, click on the profile image on upper right section and select \"My Account\"\n",
    "# Scroll down to the API section and click on \"Create New API Token\"\n",
    "# Then, open the downloaded file, you will found your api key there.\n",
    "\n",
    "api_token = {\"username\":\"kaggleUSERNAME\",\"key\":\"kaggleAPIKEY\"}\n",
    "\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "!mkdir /content\n",
    "with open('/content/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "!chmod 600 /content/kaggle.json\n",
    "!mkdir ~/.kaggle\n",
    "!cp /content/kaggle.json ~/.kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xDOxeBKihdgd"
   },
   "source": [
    "## Simple K-Nearest Neighbour on CIFAR-10 dataset\n",
    "---\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. \n",
    "\n",
    "![alt text](https://kaggle2.blob.core.windows.net/competitions/kaggle/3649/media/cifar-10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m517oxSFjpXV"
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "  \n",
    "# Download CIFAR-10 dataset from https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "urllib.request.urlretrieve ('https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz', 'cifar-10-python.tar.gz')\n",
    "with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "    tar.extractall()\n",
    "    \n",
    "# Show files in extract directory\n",
    "!ls cifar-10-batches-py/\n",
    "cifarClassName = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_NwE-Kck-FD"
   },
   "outputs": [],
   "source": [
    "# For each training batch read and concatenate into one big numpy array\n",
    "# You may find the format of CIFAR-10 in Data Layout section https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "# Train Data\n",
    "cifarImages = np.empty((0,3072), dtype=np.uint8)\n",
    "cifarLabels = np.empty((0,), dtype=np.uint8)\n",
    "for batchNo in range(1,6):\n",
    "  dataDict = unpickle('cifar-10-batches-py/data_batch_'+str(batchNo))\n",
    "  cifarImages = np.vstack((cifarImages, dataDict[b'data']))\n",
    "  cifarLabels = np.hstack((cifarLabels, dataDict[b'labels']))\n",
    "print('Image Array Shape:', cifarImages.shape)\n",
    "print('Label Array Shape:',cifarLabels.shape)\n",
    "\n",
    "# Test Data\n",
    "dataDict = unpickle('cifar-10-batches-py/test_batch')\n",
    "cifarTestImages = dataDict[b'data']\n",
    "cifarTestLabels = np.array(dataDict[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfVk8li1bZ24"
   },
   "outputs": [],
   "source": [
    "# Show samples from CIFAR-10\n",
    "randIdxs = np.random.permutation(cifarLabels.shape[0])[0:5]\n",
    "randomImages = np.empty((32,0,3), dtype=np.uint8)\n",
    "randomImageClasses = []\n",
    "for randIdx in randIdxs:\n",
    "  randomImages = np.hstack((randomImages, cifarImages[randIdx,:].reshape(3,32,32).transpose(1,2,0)))\n",
    "  randomImageClasses.append(cifarClassName[cifarLabels[randIdx]])\n",
    "plt.imshow(randomImages)\n",
    "plt.show()\n",
    "print(randomImageClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-1aDV0awxMT"
   },
   "source": [
    "Compute the L1 Distance between unknown instance from test image and training images. Given given two images and representing them as vectors $I_1$ and $I_2$, the L1 distance can be calculated by using the following equation.\n",
    "\\begin{equation}d_1(I_1,I_2) = \\sum|I_1-I_2| \\end{equation}\n",
    "\n",
    "Pick the k-nearest class as the answer, where k = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gkyxn_bxeC5N"
   },
   "outputs": [],
   "source": [
    "testIdx = 2\n",
    "unknownInstance = cifarTestImages[testIdx,:]\n",
    "unknownInstanceImage = unknownInstance.reshape(3,32,32).transpose(1,2,0)\n",
    "print('Ground Truth Class:',cifarClassName[cifarTestLabels[testIdx]])\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(unknownInstanceImage)\n",
    "plt.show()\n",
    "\n",
    "### FILL HERE ###\n",
    "\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOYizVCdvvUM"
   },
   "outputs": [],
   "source": [
    "## Compute the accuracy on test set ##\n",
    "## FILL HERE ##\n",
    "\n",
    "#print('Using L1 Distance Accuracy:',L1DistAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYOwhxBdQPka"
   },
   "source": [
    "L2 Distance between unknown instance from test image and training images. Given given two images and representing them as vectors $I_1$ and $I_2$, the L2 distance can be calculated by using the following equation.\n",
    "\\begin{equation}d_2(I_1,I_2) = \\sqrt{\\sum(I_1-I_2)^2} \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jnn0UZREv-5T"
   },
   "outputs": [],
   "source": [
    "## Try to adjust k and using other distance matrix (may be L2)\n",
    "## Compare the output accuracy with default setting\n",
    "## FILL HERE ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Etdsja4mYYMp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFze4Xi26gxg"
   },
   "source": [
    "## Quick PyTorch Tensor Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfemFDVdD6ms"
   },
   "outputs": [],
   "source": [
    "# You can use any command you use in numpy with torch Tensor\n",
    "tempTensor = torch.arange(100,125)\n",
    "print(tempTensor)\n",
    "tempTensor = tempTensor.reshape(5,5)\n",
    "\n",
    "# Reshape\n",
    "print('Reshape Output:',tempTensor,'Tensor Shape:',tempTensor.shape)\n",
    "# Tensor Indexing\n",
    "print(tempTensor[:,1:3])\n",
    "\n",
    "# Find min,max value\n",
    "print('Min val:',torch.min(tempTensor),'Max val:',torch.max(tempTensor))\n",
    "# Find min,max idx\n",
    "print('Min val idx:',torch.argmin(tempTensor),'Max val idx:',torch.argmax(tempTensor))\n",
    "\n",
    "# All Ones\n",
    "allOneTensor = torch.ones((3,3)) * 7\n",
    "# All Zeros\n",
    "allZeroTensor = torch.zeros((3,3))\n",
    "# Concatenate\n",
    "concatTensor = torch.cat((allOneTensor,allZeroTensor), dim=0)\n",
    "\n",
    "print(concatTensor,'Tensor Shape:', concatTensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntqqOwbIH_Ai"
   },
   "outputs": [],
   "source": [
    "# Autograd Feature\n",
    "x = torch.ones((1), requires_grad=True)*9\n",
    "print('x:',x)\n",
    "y = (x**2)+1\n",
    "print('y:',y)\n",
    "print('dy/dx',torch.autograd.grad(y,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_N0ekD9S5r8b"
   },
   "outputs": [],
   "source": [
    "# Convert Between PyTorch Tensor and Numpy Array\n",
    "cifarImagesTensor = torch.from_numpy(cifarImages)\n",
    "convertBackNp = cifarImagesTensor.numpy()\n",
    "print(type(cifarImagesTensor), type(convertBackNp))\n",
    "\n",
    "# Upload to GPU\n",
    "cifarImageTensor_GPU = cifarImagesTensor.cuda()\n",
    "# Download back to CPU\n",
    "cifarImageTensor_CPU = cifarImageTensor_GPU.cpu()\n",
    "print('cifarImageTensor_GPU ==>',cifarImageTensor_GPU.device,'cifarImageTensor_CPU ==>', cifarImageTensor_CPU.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_6_vu7GODN1"
   },
   "source": [
    "## Image Classification using Convolutional Neural Network\n",
    "In this section we will implement the famous LeNet-5 structure using PyTorch and trained on CIFAR-10 dataset.\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/2000/1*1TI1aGBZ4dybR6__DI9dzA.png)\n",
    "\n",
    "You can see the list of PyTorch available layers here => https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKIWK0rVc0ub"
   },
   "source": [
    "### LeNet 5 Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9e1ryUqDOHdw"
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LeNet5,self).__init__()\n",
    "    self.c1 = nn.Conv2d(3, 6, kernel_size=(5, 5)) \n",
    "    self.s2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "    self.c3 = nn.Conv2d(6, 16, kernel_size=(5, 5))\n",
    "    self.s4 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "    self.c5 = nn.Linear(16*5*5, 120)\n",
    "    self.f6 = nn.Linear(120, 84)\n",
    "    self.f7 = nn.Linear(84, 10)\n",
    "  def forward(self,x, debug=False):\n",
    "\n",
    "    x = F.relu(self.c1(x))\n",
    "    x = self.s2(x)\n",
    "    \n",
    "    x = F.relu(self.c3(x))\n",
    "    x = self.s4(x)\n",
    "    \n",
    "    # Flatten\n",
    "    x = x.view(x.size(0),-1)\n",
    "    \n",
    "    x = F.relu(self.c5(x))\n",
    "    \n",
    "    x = F.relu(self.f6(x))\n",
    "    x = self.f7(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4tOPRbX_c6Ct"
   },
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0M8wOQVLT_7Q"
   },
   "outputs": [],
   "source": [
    "cifarClassName = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "## Utilize the downloaded dataset ##\n",
    "class CIFAR10Loader(data.Dataset):\n",
    "    def __init__(self, cifarDatasetPath='cifar-10-batches-py/',train=True, transform=None):\n",
    "      self.transform = transform\n",
    "      \n",
    "      if train:\n",
    "        # Train Data\n",
    "        self.cifarImages = np.empty((0,3072), dtype=np.uint8)\n",
    "        self.cifarLabels = np.empty((0,), dtype=np.uint8)\n",
    "        for batchNo in range(1,6):\n",
    "          dataDict = unpickle(cifarDatasetPath+'/data_batch_'+str(batchNo))\n",
    "          self.cifarImages = np.vstack((cifarImages, dataDict[b'data']))\n",
    "          self.cifarLabels = np.hstack((cifarLabels, dataDict[b'labels']))\n",
    "      \n",
    "      else:\n",
    "        # Test Data\n",
    "        dataDict = unpickle(cifarDatasetPath+'/test_batch')\n",
    "        self.cifarImages = dataDict[b'data']\n",
    "        self.cifarLabels = np.array(dataDict[b'labels'])\n",
    "        \n",
    "      # Transfrom from (x,3072) ==> (32,32,3,x)\n",
    "      self.cifarImages = self.cifarImages.reshape(-1,3,32,32).transpose(2,3,1,0)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.cifarImages[:,:,:,idx]\n",
    "        label = self.cifarLabels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cifarLabels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lBBaeMIMdXe2"
   },
   "source": [
    "###Dataset Transformer \n",
    "You can see the list of image augmentation algorithms here ==> https://pytorch.org/docs/stable/torchvision/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQ1wd5wwcSob"
   },
   "outputs": [],
   "source": [
    "def transformer(image):\n",
    "    image = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.406, 0.456), (0.229, 0.225, 0.224)),\n",
    "        #transforms.RandomHorizontalFlip(p=0.5),\n",
    "    ])(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZioPEbrSYbg5"
   },
   "outputs": [],
   "source": [
    "cifar10Train = CIFAR10Loader(transform = transformer)\n",
    "cifar10Test = CIFAR10Loader(train = False, transform = transformer)\n",
    "cifar10TrainLoader = data.DataLoader(dataset=cifar10Train, batch_size=128,num_workers=4,shuffle=True)\n",
    "cifar10TestLoader = data.DataLoader(dataset=cifar10Train, batch_size=128,num_workers=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Rs9lAfNd4qS"
   },
   "source": [
    "### Create network, optimizer and training loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cX1XgKN-ZkjL"
   },
   "outputs": [],
   "source": [
    "net = LeNet5().cuda()\n",
    "net.train()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mc6ytFyCe2oE"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQmJJh80aVyw"
   },
   "outputs": [],
   "source": [
    "print('== Start Training ==')\n",
    "\n",
    "bestLoss = float('Inf')\n",
    "totalEpoch = 20\n",
    "outputModelFile = 'bestCIFAR10.pth'\n",
    "\n",
    "for epoch in range(0,totalEpoch):\n",
    "  totalLoss = 0\n",
    "  for batchIdx,(image,label) in enumerate(cifar10TrainLoader):\n",
    "    image, label = image.cuda(), label.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward + backward + optimize\n",
    "    output = net(image)\n",
    "    loss = criterion(output, label)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    totalLoss+=loss.item()\n",
    "    \n",
    "  # Loss decrease, we should save the model\n",
    "  totalLoss = totalLoss/len(cifar10TrainLoader)\n",
    "  if totalLoss < bestLoss:\n",
    "    print('Saving..')\n",
    "    bestLoss = totalLoss\n",
    "    state = {\n",
    "        'model': net.state_dict(),\n",
    "        'loss': bestLoss,\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    torch.save(state, outputModelFile)\n",
    "    \n",
    "    \n",
    "  print(epoch+1,'/',str(totalEpoch),'Batch Loss:',totalLoss)\n",
    "  \n",
    "print('== Training Finish ==')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Xr3KRo-zzjf"
   },
   "source": [
    "### Utilize best model from file \n",
    "Perform one shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9raWN--fgl0"
   },
   "outputs": [],
   "source": [
    "# Defined new model\n",
    "bestNet = LeNet5().cuda()\n",
    "checkpoint = torch.load('bestCIFAR10.pth')\n",
    "bestNet.load_state_dict(checkpoint['model'])\n",
    "bestNet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvrkQDCMy3NF"
   },
   "outputs": [],
   "source": [
    "testIdx = 2\n",
    "unknownInstance = cifarTestImages[testIdx,:]\n",
    "unknownInstanceImage = unknownInstance.reshape(3,32,32).transpose(1,2,0)\n",
    "print('Ground Truth Class:',cifarClassName[cifarTestLabels[testIdx]])\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(unknownInstanceImage)\n",
    "plt.show()\n",
    "\n",
    "# The input to network must be 4D Tensor, Eg. you can feed multiple images at once into the network\n",
    "testImage = transformer(unknownInstanceImage).unsqueeze(0).cuda()\n",
    "print('testImage Size ==>',testImage.shape)\n",
    "\n",
    "# Feed forward to network and fetch back result to memory\n",
    "predicted = F.softmax(bestNet(testImage)).cpu().detach().numpy()[0]\n",
    "print('Raw Predicted Output', predicted)\n",
    "\n",
    "# Pick the max value location in array and compare back to class name\n",
    "predictedClassNo = np.argmax(predicted)\n",
    "predictedProb = predicted[predictedClassNo]\n",
    "print('Predicted Class:',cifarClassName[predictedClassNo], '==>',predictedProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gPKpHQ8402r"
   },
   "source": [
    "### Compute model accuracy\n",
    "This block is your show time. Fill the code to compute the accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Q62cScy42Yl"
   },
   "outputs": [],
   "source": [
    "### FILL HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASmbUR5R5qvE"
   },
   "source": [
    "### Assignment 1 : Improve the CIFAR-10 classifier accuracy\n",
    "\n",
    "From the above section, you can design, train, and test your model on the well-known CIFAR-10 dataset. Your today task is to implement methods to increase the accuracy of CIFAR-10 classifier. Any method can be used and internet is your friend. Nevertheless, you must state the reasons and show the numerical expeimental results on this CIFAR-10 dataset. Don't forget to show your work in step in the below block.\n",
    "\n",
    "** Do not use test data to train your model! -__-**\n",
    "\n",
    "\n",
    "Hint : State-of-the-art on CIFAR-10 ==> http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHresmMo8l7w"
   },
   "outputs": [],
   "source": [
    "## State your improvement here ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2QDEIN-5zpz"
   },
   "outputs": [],
   "source": [
    "### FILL CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5o2wpqa82Vk"
   },
   "source": [
    "# Object detection using sliding window based classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4HEJNjPWGBSI"
   },
   "source": [
    "In this section, we will create a sliding window based car model detection by using the standford car dataset ==> https://www.kaggle.com/jutrera/stanford-car-dataset-by-classes-folder/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WFotJ038ttD"
   },
   "outputs": [],
   "source": [
    "# Download Standford car dataset using kaggle api and \n",
    "!kaggle datasets download -d jutrera/stanford-car-dataset-by-classes-folder\n",
    "!unzip -o stanford-car-dataset-by-classes-folder.zip\n",
    "!unzip -o -q car_data.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKjT7hphndet"
   },
   "outputs": [],
   "source": [
    "# Keep only first 20 classes\n",
    "keepClass = 20\n",
    "import shutil\n",
    "\n",
    "carModelName = []\n",
    "with open('names.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for idx,row in enumerate(readCSV):\n",
    "        if idx < keepClass: \n",
    "          carModelName.append(row[0])\n",
    "        else:\n",
    "          shutil.rmtree('car_data/train/'+row[0].strip().replace('/','-'),ignore_errors=True)\n",
    "          shutil.rmtree('car_data/test/'+row[0].strip().replace('/','-'),ignore_errors=True)\n",
    "print(carModelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9dxVK1sPEK7"
   },
   "source": [
    "## Dataset Loader and Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8CdYtWyNavC"
   },
   "outputs": [],
   "source": [
    "# Dataset Directory structure is in the following format : car_data/<set>/<car_model>\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.405],\n",
    "                         std=[0.229, 0.224, 0.225]) # Imagenet datset mean and std\n",
    "])\n",
    "\n",
    "carTrain = datasets.ImageFolder('car_data/train', transform=transformer)\n",
    "carTest = datasets.ImageFolder('car_data/test',transform=transformer)\n",
    "carTrainLoader = data.DataLoader(dataset=carTrain, batch_size=64,num_workers=0,shuffle=True)\n",
    "carTestLoader = data.DataLoader(dataset=carTest, batch_size=64,num_workers=0,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikNOswHzSI78"
   },
   "source": [
    "## Modify Resnet-18 pretrained model\n",
    "In this section, we will modify pretrained model on ImageNet dataset to match with the number of our classes (196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lRI5VsJHDaB"
   },
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "print('=== Before ===')\n",
    "print(resnet18)\n",
    "print('=== After ===')\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features,keepClass)\n",
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0mVIZktT_4Q"
   },
   "source": [
    "## Create network, optimizer and training loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkvr-VRsUAnf"
   },
   "outputs": [],
   "source": [
    "resnet18.cuda().train()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(resnet18.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "galsiJEiTok_"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQgiBSIxQST5"
   },
   "outputs": [],
   "source": [
    "print('== Start Training ==')\n",
    "\n",
    "bestLoss = float('Inf')\n",
    "totalEpoch = 20\n",
    "outputModelFile = 'bestCar.pth'\n",
    "\n",
    "for epoch in range(0,totalEpoch):\n",
    "  totalLoss = 0\n",
    "  trainProgressBar = tqdm(enumerate(carTrainLoader),total=len(carTrainLoader),position=0)\n",
    "  for batchIdx,(image,label) in trainProgressBar:\n",
    "    image, label = image.cuda(), label.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward + backward + optimize\n",
    "    output = resnet18(image)\n",
    "    loss = criterion(output, label)\n",
    "    #print(output.shape)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    totalLoss+=loss.item()\n",
    "    avgLoss = totalLoss/(batchIdx+1)\n",
    "   \n",
    "    \n",
    "    trainProgressBar.set_description('avg_loss: %.3f' % avgLoss)\n",
    "                                                                                                                                   \n",
    "  # Loss decrease, we should save the model\n",
    "  totalLoss = totalLoss/len(carTrainLoader)\n",
    "  if totalLoss < bestLoss:\n",
    "    print('Saving..')\n",
    "    bestLoss = totalLoss\n",
    "    state = {\n",
    "        'model': resnet18.state_dict(),\n",
    "        'loss': bestLoss,\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    torch.save(state, outputModelFile)\n",
    "    \n",
    "    \n",
    "  print(epoch+1,'/',str(totalEpoch),'Epoch Loss:',totalLoss)\n",
    "  \n",
    "print('== Training Finish ==')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjNH0lmVjntv"
   },
   "source": [
    "## Single Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xsl3o3YjrAj"
   },
   "outputs": [],
   "source": [
    "# Defined new model\n",
    "bestCarNet = models.resnet18(pretrained=True)\n",
    "bestCarNet.fc = nn.Linear(resnet18.fc.in_features,keepClass)\n",
    "checkpoint = torch.load('bestCar.pth')\n",
    "print(checkpoint['loss'])\n",
    "bestCarNet.load_state_dict(checkpoint['model'])\n",
    "bestCarNet.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWz3LjVxkTW4"
   },
   "outputs": [],
   "source": [
    "inputImage = cv2.imread('car_data/test/AM General Hummer SUV 2000/00076.jpg')\n",
    "inputImageRGB = Image.fromarray(cv2.cvtColor(inputImage, cv2.COLOR_BGR2RGB))\n",
    "inputImageTensor = transformer(inputImageRGB).unsqueeze(0).cuda()\n",
    "\n",
    "# Feed forward to network and fetch back result to memory\n",
    "predicted = F.softmax(bestCarNet(inputImageTensor)).cpu().detach().numpy()[0]\n",
    "print('Raw Predicted Output', predicted)\n",
    "\n",
    "# Pick the max value location in array and compare back to class name\n",
    "predictedClassNo = np.argmax(predicted)\n",
    "print('Predicted Class:',carModelName[predictedClassNo], '==>',predicted[predictedClassNo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YILfSqbieRdQ"
   },
   "source": [
    "## Compute model accuracy\n",
    "This block is your show time. Fill the code to compute the accuracy of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bpo17t5NUQwU"
   },
   "outputs": [],
   "source": [
    "## FILL HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RNrd9vGPfYZ3"
   },
   "source": [
    "## Asssignment 2 : Sliding Window based Detector\n",
    "In this section, you should be able to write a car model detector by using your trained car model classifier.  The diagram of designed detector would be\n",
    "\n",
    "Multiscale Inpue Image --> Sliding Window --> Car Model Classifier --> Non-Maxima-Supession (NMS) --> Predicted Car Model and its coordinate\n",
    "\n",
    "- You can use the entire training set in \"car_data/train/\" as a training data. \n",
    "\n",
    "- Perform an evaluation by using Intersection over Union (IOU) criterion over first k classes (k will be annouced in class) , predicted box will be considered as correct if IOU > 0.5.\n",
    "- You can use any resorces on internet but you must give a proper credit.\n",
    "- You can make any modification to trained model to improve overall accuracy.\n",
    "\n",
    "- ** Please submit result in the following python pickle format and use this guide https://wiki.python.org/moin/UsingPickle to save your work to file. **\n",
    "        Example:\n",
    "        output['00001.jpg'] = [x,y,w,h,classNo]\n",
    "        output['00002.jpg'] = [x,y,w,h,classNo]\n",
    "        output['00003.jpg'] = [] (No Answer)\n",
    "       \n",
    "       \n",
    "- **(Optional) Top-3 in class accuracy will earn extra points.**\n",
    "\n",
    "**Don't forget to show your work in step in the below block.**\n",
    "Expected Algorithm (Image from : https://www.pyimagesearch.com/2015/03/23/sliding-windows-for-object-detection-with-python-and-opencv/ )\n",
    "![Sliding Window Based Detector](https://www.pyimagesearch.com/wp-content/uploads/2015/03/sliding-window-animated-adrian.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fwx6TaMDfcmw"
   },
   "outputs": [],
   "source": [
    "## State your algorithm & improvement here ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4txczyJexYXM"
   },
   "outputs": [],
   "source": [
    "## FILL CODE HERE ##"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Lab 6 - Convolutional Neural Network.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
